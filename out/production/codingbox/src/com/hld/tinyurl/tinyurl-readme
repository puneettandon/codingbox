Tiny-Url System Design


2 Functional Requirements
1. Given a long URL, you get a short URL, so when somebody wants to shorten the url

2. When somebody hits the a short url then you basically redirect to the longer url


Non-Functional
This service needs to be highly available and should work at very low latency
Because Suppose , we are building it for facebook or twitter

Bad experience if it take more time

--> What should be the length of our short URL
    - Depends on the scale that we need to build this system for
    - If couple hundred of urls then 2-3 characters are more than enough
    - If building for google scale or facebook scale, then we need to think of length of short urls and
      should not run out of these short urls
    - Another option - we build a system agnostic of the length and we start from somewhere
      and it keeps on incrementing.
    - Let's start with fixed length to start

Question for interviewer

    1. what is the traffic you are looking at?
    2. How many unique Urls will come to you for shortening every day,month, or some number
    3. And until what duration you need to support that?

   Q-  Assume once a url is converted to shorter url , you need to save it for at least next ten years
    Suppose X number of requests per second

    x- per seconds
    x * 60  per minute
    x * 60 * 60 per hour
    x * 60 * 60 * 24 per day
    x * 60 * 60 * 24 * 365 per year
    x * 60  * 60 * 24 * 365 * 10  in 10 year
    you should be able to build a system which can handle these number of unique requests.
    x * 60  * 60 * 24 * 365 * 10 = y

    Let's say this number is 'Y'.Now the next question to ask is what all characters can you include
    in the short url? should it be just numbers? could it be alphabets?
    could it be capital alphabets and small case alphabets? what all is allowed?


    Generally [A-Z][a-z] and numbers[0-9]  (or you can interviewer)
    so total 62 characters

    Now you need to come up with some length which can handle y number of urls ( with unique combination)


    Let's just say if length was 1 , then you can support 62 URLs
            1  --->   62
            2  --->   62 ^ 2
                      62 ^ n > y
            n = log62 y
            suppose if this number comes to be 4.5 , then you take n = 5
            so you create short urls of length 5

            62 ^ 6 = 58 billion
            62 ^ 7 = 3.5 trillion

            Depending upon what is your case , you can come up with some length

            Generally, short urls use 7 characters

----------------------------------------------------------------------------------------------------------------------------------------------

Architecture to solve this problem


added tiny - url png  file

There is a UI which takes long url as input and
gives back the short url . So it wil call short url service
There will be multiple instances of this service which generates a short url and
stores it in a database
and returns the short url to the customer
On the other side, this could also be used when somebody hits a short url wherein
the short url service would fetch the long urls from the database and then
redirect the users to the longer url

--------------------------------------------------------------------------------------------------------------------------------------------




Collision Scenario -

    If multiple Short URL service generates same short url
    Example -  111
               111

    We cannot have one short url pointing to two long urls

    Soln1 - Check in database and then retry
            Not efficient solution

    Soln2 - We need a predictable way to generate a short url knowing that
            there would be no collisions at all.
            1. Using feature of Redis
                   We use redis cluster and all of these services request a number from redis
                   Redis makes sure that it will always return a unique number.
                   so basically what it will do is it will start counting from 1
                   all the way upto billions, trillions, whatever
                   And each it gets the request,it increments the counter and responds back.
                   We will make sure that all of these guys are getting unique numbers
                   and from unique number at base 10, they can convert to base 62 and
                   generate the short url.

                   Issue with above approach
                    1. Redis under huge amount of load
                    2. In all the requests that have to generate a short url,
                       this redis become a single point of failure and there is no backup to it
                       If it goes down then there is no way to recover
                       If scale becomes beyond the capacity of one redis machine, then much problem
                       Effect latency of the system
                    3. Another option - multiple redis - will give high availability and better performance
                       Works fine till These Redis don't start generating duplicate numbers
                       If both the redis are starting from the same index , again they will start generating duplicates
                       Soln - Give one redis one series , other redis other series
                       Issue - What if to introduce third Redis
                                Need someone to manage series


    Soln3 - Advanced System which can generate unique urls without a redis without having single point of failure
            1. One of the simple is to assign ranges to each of the machines
               This short url service will request a token range from token service
               Each time token service gets a request,it run on a single threaded model
               and it will give a range to any of the service instances.
               short url service 1 ---> (1-1000)
               Now short url service 2 will also call token service ( all services will call token service on startup
                or when they are running out of range)
               short url service 2 ---> (1001-2000)
               Token service can be built on top of mysql because it runs at very low scale

               Let's say, a request reaches this service.It takes first number 1001 converts into base 62
               and saves in casandra and returns the output

               Token service will keep range as a record and and keep a flag whether it is assigned or not.
               Allocate millions of tokens at once so better performance
               Token service will be distributed in multiple geographies at least and multiple data centers
               so that this doesn't become a single point of failure.

               Issue with this approach
               1. Suppose short url service is assigned (5001-6000) range, started working for a while ,
                   used a couple of tokens and then it kind of got shut down and died.(may because of
                   out of memory error and this process got killed)Then what happens to those tokens
                   As there is no track record of how many tokens being used.

                   Real - 3.5T
                   Don't need to track each --- will get new range if get lost.

                   This Long url to short url path


         -------------------------------------------------------------------------------------------------------------------------


    Short Url ---> to Long Url

        --> When short url is hit, all you do is - you get a request in short url, you hit your database
            and you get the longer url, you will send it back to this service(short url).
            This service does a redirect and the user redirect to the main url.



    Why Casandra as a databse?
    Ideally any database  - which can handle 3.5T (unique urls).
    MySQL at these number of records would some give problems. we shard it probably and make it work.
    Cassandra will sure for work

------------------------------------------------------------------------------------------------------------------------------------

    Further Enhancements-

    Above built system, does not give us any metrics about how it is being used,
    what kind of urls are the top most urls
    what kind of geographies people come from

    For example,whenever a person is generating a short url,wouldn't it be nice,if we can tell them
    what kind of geography do your people come from or
    what kind of hits are you getting or
    what kind of user agents or devices the people are connecting from.

    All of those things would be valuable information for any person who is generating a short url.
    Similarly for us, if we have multiple data centers. Suppose 4 data centers and want to choose any 2 of them
    as primary and 2 as standby data centers and they are spread across the globe.
    Decide which one as primary and which one as stand by
    Could make data driven decision depending upon the traffic we are getting.
    Data centers close to those geographies can be made as primary

    -----------------------------------------------------------------

    Analytics for the system
    Each time request comes to us that will come with lot of attributes.
    Give us some origin header what is platform from where this request has come in. also user-agent(android,ios or browser)
    and also source ip address
    All of these information ,before sending out the response, we will also put that into a kafka,which will be used to
    power tha analytics.
    But it can impact latency if we put each request on kafka.
    What instead we could do as a fairly nice solution is make the kafka request as a parallel call.
    So we can have a different thread, in which we can send the kafka write and return back to the user.
    and asynchronously, it can be returned to kafka.

    Issue in asynchronous thing, Potential possibility kafka write could fail , for whatever reason, and
    and you have returned back to the user so you will miss certain analytics.
    In this kind of system payment is not involved , it is simple analytics,we should be okay if we are losing
    out certain events.But it's ok if we lose some.

    Further Improvements -
    Write to kafka involve I/O operation,CPU operation,Network Transfer involved.
    Can we avoid all of this.
    We could may be aggregate that information locally in a machine
    So, may be you can have a Queue or some kind of a data structure in which you are persisting each record
    that we got a request for this short URL with count 1.
    The request  again  comes in, you increment the count to 2.
    Whenever the size of the data structure crosses some threshold or you could do it on some time basis,
    saying every 10 seconds you will flush that.
    So now you can flush that data into that data structure, into one call in kafka.
    Basically you are reducing the I/O that you are doing with each request and doing it as a batch write.
    Drive much performance with single machine.
    May lose not just one event but a lot of events.


















